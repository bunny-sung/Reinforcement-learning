{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sarsa.ipynb",
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ctarTLLGewt"
      },
      "source": [
        "## On-policy learning and SARSA\n",
        "\n",
        "_This notebook builds upon `qlearning.ipynb`, or to be exact your implementation of QLearningAgent._\n",
        "\n",
        "The policy we're gonna use is epsilon-greedy policy, where agent takes optimal action with probability $(1-\\epsilon)$, otherwise samples action at random. Note that agent __can__ occasionally sample optimal action during random sampling by pure chance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgqIbHnXGew4",
        "outputId": "9b03bf5d-21e2-425a-923e-9ef1093eaf55"
      },
      "source": [
        "import sys, os\n",
        "if 'google.colab' in sys.modules and not os.path.exists('.setup_complete'):\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh -O- | bash\n",
        "\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/coursera/grading.py -O ../grading.py\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/coursera/week3_model_free/submit.py\n",
        "\n",
        "    !touch .setup_complete\n",
        "\n",
        "# This code creates a virtual display to draw game images on.\n",
        "# It will have no effect if your machine has a monitor.\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
        "    !bash ../xvfb start\n",
        "    os.environ['DISPLAY'] = ':1'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting previously unselected package xvfb.\n",
            "(Reading database ... 155222 files and directories currently installed.)\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.9_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.9) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.9) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Starting virtual X frame buffer: Xvfb.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XowaObbSGew7"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DA6E3bTHGew8"
      },
      "source": [
        "You can copy your `QLearningAgent` implementation from previous notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qNRs9fHGew9"
      },
      "source": [
        "from collections import defaultdict\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class QLearningAgent:\n",
        "    def __init__(self, alpha, epsilon, discount, get_legal_actions):\n",
        "        \"\"\"\n",
        "        Q-Learning Agent\n",
        "        based on https://inst.eecs.berkeley.edu/~cs188/sp19/projects.html\n",
        "        Instance variables you have access to\n",
        "          - self.epsilon (exploration prob)\n",
        "          - self.alpha (learning rate)\n",
        "          - self.discount (discount rate aka gamma)\n",
        "\n",
        "        Functions you should use\n",
        "          - self.get_legal_actions(state) {state, hashable -> list of actions, each is hashable}\n",
        "            which returns legal actions for a state\n",
        "          - self.get_qvalue(state,action)\n",
        "            which returns Q(state,action)\n",
        "          - self.set_qvalue(state,action,value)\n",
        "            which sets Q(state,action) := value\n",
        "\n",
        "        !!!Important!!!\n",
        "        Note: please avoid using self._qValues directly. \n",
        "            There's a special self.get_qvalue/set_qvalue for that.\n",
        "        \"\"\"\n",
        "\n",
        "        self.get_legal_actions = get_legal_actions\n",
        "        self._qvalues = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "        self.alpha = alpha\n",
        "        self.epsilon = epsilon\n",
        "        self.discount = discount\n",
        "\n",
        "    def get_qvalue(self, state, action):\n",
        "        \"\"\" Returns Q(state,action) \"\"\"\n",
        "        return self._qvalues[state][action]\n",
        "\n",
        "    def set_qvalue(self, state, action, value):\n",
        "        \"\"\" Sets the Qvalue for [state,action] to the given value \"\"\"\n",
        "        self._qvalues[state][action] = value\n",
        "\n",
        "    #---------------------START OF YOUR CODE---------------------#\n",
        "\n",
        "    def get_value(self, state):\n",
        "        \"\"\"\n",
        "        Compute your agent's estimate of V(s) using current q-values\n",
        "        V(s) = max_over_action Q(state,action) over possible actions.\n",
        "        Note: please take into account that q-values can be negative.\n",
        "        \"\"\"\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "\n",
        "        # If there are no legal actions, return 0.0\n",
        "        if len(possible_actions) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        value = np.NINF\n",
        "        for action in possible_actions:\n",
        "            value = np.maximum(value, self.get_qvalue(state,action))\n",
        "\n",
        "        return value\n",
        "\n",
        "    def update(self, state, action, reward, next_state):\n",
        "        \"\"\"\n",
        "        You should do your Q-Value update here:\n",
        "           Q(s,a) := (1 - alpha) * Q(s,a) + alpha * (r + gamma * V(s'))\n",
        "        \"\"\"\n",
        "\n",
        "        # agent parameters\n",
        "        gamma = self.discount\n",
        "        learning_rate = self.alpha\n",
        "\n",
        "        new_Q_value = (1 - learning_rate) * self.get_qvalue(state,action) + learning_rate * (reward + gamma * self.get_value(next_state))\n",
        "        self.set_qvalue(state, action, new_Q_value)\n",
        "\n",
        "    def get_best_action(self, state):\n",
        "        \"\"\"\n",
        "        Compute the best action to take in a state (using current q-values). \n",
        "        \"\"\"\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "\n",
        "        # If there are no legal actions, return None\n",
        "        if len(possible_actions) == 0:\n",
        "            return None\n",
        "\n",
        "        value = np.NINF\n",
        "        best_action = possible_actions[0]\n",
        "        for action in possible_actions:\n",
        "            if (self.get_qvalue(state, action) > value):\n",
        "                best_action = action\n",
        "                value = self.get_qvalue(state, action)\n",
        "        \n",
        "        return best_action\n",
        "\n",
        "    def get_action(self, state):\n",
        "        \"\"\"\n",
        "        Compute the action to take in the current state, including exploration.  \n",
        "        With probability self.epsilon, we should take a random action.\n",
        "            otherwise - the best policy action (self.getPolicy).\n",
        "\n",
        "        Note: To pick randomly from a list, use random.choice(list). \n",
        "              To pick True or False with a given probablity, generate uniform number in [0, 1]\n",
        "              and compare it with your probability\n",
        "        \"\"\"\n",
        "\n",
        "        # Pick Action\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "        action = None\n",
        "\n",
        "        # If there are no legal actions, return None\n",
        "        if len(possible_actions) == 0:\n",
        "            return None\n",
        "\n",
        "        # agent parameters:\n",
        "        epsilon = self.epsilon\n",
        "\n",
        "        p= random.random() \n",
        "        if p < epsilon: \n",
        "            chosen_action = random.choice(possible_actions)\n",
        "        else:\n",
        "            chosen_action = self.get_best_action(state)\n",
        "\n",
        "        return chosen_action"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9nCj6WeGew-"
      },
      "source": [
        "Now we gonna implement Expected Value SARSA on top of it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeCjf7N6Gew_"
      },
      "source": [
        "class EVSarsaAgent(QLearningAgent):\n",
        "    \"\"\" \n",
        "    An agent that changes some of q-learning functions to implement Expected Value SARSA. \n",
        "    Note: this demo assumes that your implementation of QLearningAgent.update uses get_value(next_state).\n",
        "    If it doesn't, please add\n",
        "        def update(self, state, action, reward, next_state):\n",
        "            and implement it for Expected Value SARSA's V(s')\n",
        "    \"\"\"\n",
        "\n",
        "    def get_value(self, state):\n",
        "        \"\"\" \n",
        "        Returns Vpi for current state under epsilon-greedy policy:\n",
        "          V_{pi}(s) = sum _{over a_i} {pi(a_i | s) * Q(s, a_i)}\n",
        "\n",
        "        Hint: all other methods from QLearningAgent are still accessible.\n",
        "        \"\"\"\n",
        "        epsilon = self.epsilon\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "\n",
        "        # If there are no legal actions, return 0.0\n",
        "        if len(possible_actions) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        #<YOUR CODE: see docstring>\n",
        "        state_value = 0\n",
        "        for action in possible_actions:\n",
        "            state_value += 1/(len(possible_actions)) * self.get_qvalue(state, action)\n",
        "\n",
        "        return state_value"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Es2AGHqlGexA"
      },
      "source": [
        "### Cliff World\n",
        "\n",
        "Let's now see how our algorithm compares against q-learning in case where we force agent to explore all the time.\n",
        "\n",
        "<img src=https://github.com/yandexdataschool/Practical_RL/raw/master/yet_another_week/_resource/cliffworld.png width=600>\n",
        "<center><i>image by cs188</i></center>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcq6_BceGexB",
        "outputId": "9b993363-aeaf-4890-e911-4ffaf4eb137d"
      },
      "source": [
        "import gym\n",
        "import gym.envs.toy_text\n",
        "env = gym.envs.toy_text.CliffWalkingEnv()\n",
        "n_actions = env.action_space.n\n",
        "\n",
        "print(env.__doc__)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    This is a simple implementation of the Gridworld Cliff\n",
            "    reinforcement learning task.\n",
            "\n",
            "    Adapted from Example 6.6 (page 106) from Reinforcement Learning: An Introduction\n",
            "    by Sutton and Barto:\n",
            "    http://incompleteideas.net/book/bookdraft2018jan1.pdf\n",
            "\n",
            "    With inspiration from:\n",
            "    https://github.com/dennybritz/reinforcement-learning/blob/master/lib/envs/cliff_walking.py\n",
            "\n",
            "    The board is a 4x12 matrix, with (using Numpy matrix indexing):\n",
            "        [3, 0] as the start at bottom-left\n",
            "        [3, 11] as the goal at bottom-right\n",
            "        [3, 1..10] as the cliff at bottom-center\n",
            "\n",
            "    Each time step incurs -1 reward, and stepping into the cliff incurs -100 reward\n",
            "    and a reset to the start. An episode terminates when the agent reaches the goal.\n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjgCE61eGexC",
        "outputId": "366ee0cc-9129-4810-c03c-bf5cacaf782a"
      },
      "source": [
        "# Our cliffworld has one difference from what's on the image: there is no wall.\n",
        "# Agent can choose to go as close to the cliff as it wishes. x:start, T:exit, C:cliff, o: flat ground\n",
        "env.render()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "o  o  o  o  o  o  o  o  o  o  o  o\n",
            "o  o  o  o  o  o  o  o  o  o  o  o\n",
            "o  o  o  o  o  o  o  o  o  o  o  o\n",
            "x  C  C  C  C  C  C  C  C  C  C  T\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pRiAxvYGexC"
      },
      "source": [
        "def play_and_train(env, agent, t_max=10**4):\n",
        "    \"\"\"This function should \n",
        "    - run a full game, actions given by agent.getAction(s)\n",
        "    - train agent using agent.update(...) whenever possible\n",
        "    - return total reward\"\"\"\n",
        "    total_reward = 0.0\n",
        "    s = env.reset()\n",
        "\n",
        "    for t in range(t_max):\n",
        "        a = agent.get_action(s)\n",
        "\n",
        "        next_s, r, done, _ = env.step(a)\n",
        "        agent.update(s, a, r, next_s)\n",
        "\n",
        "        s = next_s\n",
        "        total_reward += r\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    return total_reward"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQMbSqu1GexM"
      },
      "source": [
        "agent_sarsa = EVSarsaAgent(alpha=0.25, epsilon=0.2, discount=0.99,\n",
        "                           get_legal_actions=lambda s: range(n_actions))\n",
        "\n",
        "agent_ql = QLearningAgent(alpha=0.25, epsilon=0.2, discount=0.99,\n",
        "                          get_legal_actions=lambda s: range(n_actions))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "ZWzaa1VQGexN",
        "outputId": "b34a82ad-2d7a-44ac-d583-c4533f380c0b"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "import pandas as pd\n",
        "\n",
        "def moving_average(x, span=100):\n",
        "    return pd.DataFrame({'x': np.asarray(x)}).x.ewm(span=span).mean().values\n",
        "\n",
        "rewards_sarsa, rewards_ql = [], []\n",
        "\n",
        "for i in range(5000):\n",
        "    rewards_sarsa.append(play_and_train(env, agent_sarsa))\n",
        "    rewards_ql.append(play_and_train(env, agent_ql))\n",
        "    # Note: agent.epsilon stays constant\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        clear_output(True)\n",
        "        print('EVSARSA mean reward =', np.mean(rewards_sarsa[-100:]))\n",
        "        print('QLEARNING mean reward =', np.mean(rewards_ql[-100:]))\n",
        "        plt.title(\"epsilon = %s\" % agent_ql.epsilon)\n",
        "        plt.plot(moving_average(rewards_sarsa), label='ev_sarsa')\n",
        "        plt.plot(moving_average(rewards_ql), label='qlearning')\n",
        "        plt.grid()\n",
        "        plt.legend()\n",
        "        plt.ylim(-500, 0)\n",
        "        plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EVSARSA mean reward = -25.74\n",
            "QLEARNING mean reward = -92.65\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWA2nPxTGexN"
      },
      "source": [
        "Let's now see what did the algorithms learn by visualizing their actions at every state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_pc078DGexP"
      },
      "source": [
        "def draw_policy(env, agent):\n",
        "    \"\"\" Prints CliffWalkingEnv policy with arrows. Hard-coded. \"\"\"\n",
        "    n_rows, n_cols = env._cliff.shape\n",
        "\n",
        "    actions = '^>v<'\n",
        "\n",
        "    for yi in range(n_rows):\n",
        "        for xi in range(n_cols):\n",
        "            if env._cliff[yi, xi]:\n",
        "                print(\" C \", end='')\n",
        "            elif (yi * n_cols + xi) == env.start_state_index:\n",
        "                print(\" X \", end='')\n",
        "            elif (yi * n_cols + xi) == n_rows * n_cols - 1:\n",
        "                print(\" T \", end='')\n",
        "            else:\n",
        "                print(\" %s \" %\n",
        "                      actions[agent.get_best_action(yi * n_cols + xi)], end='')\n",
        "        print()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebnPtMwaGexR",
        "outputId": "de619b0b-0bd9-48e5-c6a9-d44e99c28e0b"
      },
      "source": [
        "print(\"Q-Learning\")\n",
        "draw_policy(env, agent_ql)\n",
        "\n",
        "print(\"SARSA\")\n",
        "draw_policy(env, agent_sarsa)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q-Learning\n",
            " >  v  v  >  v  >  >  >  v  >  >  v \n",
            " >  >  >  >  >  >  >  >  >  >  >  v \n",
            " >  >  >  >  >  >  >  >  >  >  >  v \n",
            " X  C  C  C  C  C  C  C  C  C  C  T \n",
            "SARSA\n",
            " >  >  >  >  >  >  >  >  >  >  >  v \n",
            " ^  >  >  >  >  >  >  ^  ^  >  >  v \n",
            " ^  >  >  >  ^  ^  ^  ^  ^  ^  >  v \n",
            " X  C  C  C  C  C  C  C  C  C  C  T \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awrKUvnUGexR"
      },
      "source": [
        "### Submit to Coursera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kmlUHzvGexS"
      },
      "source": [
        "from submit import submit_sarsa\n",
        "submit_sarsa(rewards_ql, rewards_sarsa, 'your.email@example.com', 'YourAssignmentToken')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9Gsu1qDGexS"
      },
      "source": [
        "### More\n",
        "\n",
        "Here are some of the things you can do if you feel like it:\n",
        "\n",
        "* Play with epsilon. See learned how policies change if you set epsilon to higher/lower values (e.g. 0.75).\n",
        "* Expected Value SASRSA for softmax policy:\n",
        "$$ \\pi(a_i|s) = softmax({Q(s,a_i) \\over \\tau}) = {e ^ {Q(s,a_i)/ \\tau}  \\over {\\sum_{a_j}  e ^{Q(s,a_j) / \\tau }}} $$\n",
        "* Implement N-step algorithms and TD($\\lambda$): see [Sutton's book](http://incompleteideas.net/book/bookdraft2018jan1.pdf) chapter 7 and chapter 12.\n",
        "* Use those algorithms to train on CartPole in previous / next assignment for this week."
      ]
    }
  ]
}